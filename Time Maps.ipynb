{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Time Maps\n",
    "\n",
    "###Alternate visualization for event occurance rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from twython import Twython\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "\n",
    "Nside=256 # this is the number of bins along x and y for the histogram\n",
    "width=8 # the width of the Gaussian function along x and y when applying the blur operation\n",
    "\n",
    "H = np.zeros((Nside,Nside)) # a 'histogram' matrix that counts the number of points in each grid-square\n",
    "\n",
    "max_diff = np.max(diffs) # maximum time difference\n",
    "\n",
    "x_heat = (Nside-1)*xcoords/max_diff # the xy coordinates scaled to the size of the matrix\n",
    "y_heat = (Nside-1)*ycoords/max_diff # subtract 1 since Python starts counting at 0, unlike Fortran and R\n",
    "\n",
    "for i in range(len(xcoords)): # loop over all points to calculate the population of each bin\n",
    "    H[x_heat[i], y_heat[i]] += 1 # Increase count by 1\n",
    "    #here, the integer part of x/y_heat[i] is automatically taken\n",
    "\n",
    "H = ndi.gaussian_filter(H,width) # apply Gaussian blur\n",
    "H = np.transpose(H) # so that the orientation is the same as the scatter plot\n",
    "\n",
    "plt.imshow(H, origin='lower') # display H as an image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API allows you to gather the 3,200 most recent tweets written by a user. Using Twython, I downloaded tweets from the @FEMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "199\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "26\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "user = 'FEMA'\n",
    "twitter = Twython(APP_KEY, APP_SECRET)\n",
    "user_timeline = twitter.get_user_timeline(screen_name=user, count = 200, include_rts = 1)\n",
    "user_timeline\n",
    "tweets = []\n",
    "timestamp = []\n",
    "while len(user_timeline) != 0: \n",
    "    try:\n",
    "        user_timeline = twitter.get_user_timeline(screen_name=user,\n",
    "                                                  include_rts = 1,\n",
    "                                                  count=200,\n",
    "                                                  max_id=user_timeline[len(user_timeline)-1]['id']-1)\n",
    "    except TwythonError as e:\n",
    "        print e\n",
    "    print len(user_timeline)\n",
    "    for tweet in user_timeline:\n",
    "        # Add whatever you want from the tweet, here we just add the text\n",
    "        tweets.append(tweet['text'].encode('utf-8', ))\n",
    "        timestamp.append(tweet['created_at'].encode('utf-8'))\n",
    "        #hashtags.append(tweet['entities']['hashtags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Sep 04 19:55:14 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu Sep 03 18:33:44 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Sep 01 20:58:51 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Sep 01 20:28:20 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Sep 01 15:29:38 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tue Sep 01 11:53:29 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon Aug 31 13:35:26 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mon Aug 31 13:11:27 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun Aug 30 20:27:26 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun Aug 30 16:17:45 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sun Aug 30 14:23:48 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Aug 29 20:14:56 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Aug 29 17:42:17 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Aug 29 15:18:40 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Aug 29 14:04:38 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Aug 28 23:07:28 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fri Aug 28 22:12:09 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Aug 28 19:48:24 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Aug 28 17:46:46 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fri Aug 28 16:19:57 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri Aug 28 13:20:20 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thu Aug 27 21:41:31 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Thu Aug 27 21:11:41 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thu Aug 27 21:07:35 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Thu Aug 27 19:57:06 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thu Aug 27 19:25:14 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu Aug 27 01:48:47 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thu Aug 27 01:42:01 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wed Aug 26 21:41:24 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wed Aug 26 19:21:21 +0000 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Wed Aug 29 18:41:46 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Wed Aug 29 18:40:55 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Wed Aug 29 18:40:25 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Wed Aug 29 16:42:45 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Wed Aug 29 16:22:16 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>Wed Aug 29 16:19:39 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>Wed Aug 29 16:17:10 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Wed Aug 29 16:15:59 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>Wed Aug 29 15:36:14 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>Wed Aug 29 14:22:17 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>Wed Aug 29 13:59:02 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>Wed Aug 29 03:09:48 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Wed Aug 29 03:08:32 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>Wed Aug 29 03:06:53 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>Wed Aug 29 02:49:38 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>Wed Aug 29 00:55:49 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>Tue Aug 28 23:08:19 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>Tue Aug 28 19:30:24 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>Tue Aug 28 18:48:41 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>Tue Aug 28 18:23:41 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>Tue Aug 28 18:22:55 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>Tue Aug 28 16:35:14 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>Tue Aug 28 15:37:03 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>Tue Aug 28 15:23:30 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>Tue Aug 28 15:20:26 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>Tue Aug 28 15:09:53 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>Tue Aug 28 14:29:26 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>Tue Aug 28 13:24:09 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>Tue Aug 28 12:38:59 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>Tue Aug 28 12:38:40 +0000 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3025 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tweets\n",
       "0     Fri Sep 04 19:55:14 +0000 2015\n",
       "1     Thu Sep 03 18:33:44 +0000 2015\n",
       "2     Tue Sep 01 20:58:51 +0000 2015\n",
       "3     Tue Sep 01 20:28:20 +0000 2015\n",
       "4     Tue Sep 01 15:29:38 +0000 2015\n",
       "5     Tue Sep 01 11:53:29 +0000 2015\n",
       "6     Mon Aug 31 13:35:26 +0000 2015\n",
       "7     Mon Aug 31 13:11:27 +0000 2015\n",
       "8     Sun Aug 30 20:27:26 +0000 2015\n",
       "9     Sun Aug 30 16:17:45 +0000 2015\n",
       "10    Sun Aug 30 14:23:48 +0000 2015\n",
       "11    Sat Aug 29 20:14:56 +0000 2015\n",
       "12    Sat Aug 29 17:42:17 +0000 2015\n",
       "13    Sat Aug 29 15:18:40 +0000 2015\n",
       "14    Sat Aug 29 14:04:38 +0000 2015\n",
       "15    Fri Aug 28 23:07:28 +0000 2015\n",
       "16    Fri Aug 28 22:12:09 +0000 2015\n",
       "17    Fri Aug 28 19:48:24 +0000 2015\n",
       "18    Fri Aug 28 17:46:46 +0000 2015\n",
       "19    Fri Aug 28 16:19:57 +0000 2015\n",
       "20    Fri Aug 28 13:20:20 +0000 2015\n",
       "21    Thu Aug 27 21:41:31 +0000 2015\n",
       "22    Thu Aug 27 21:11:41 +0000 2015\n",
       "23    Thu Aug 27 21:07:35 +0000 2015\n",
       "24    Thu Aug 27 19:57:06 +0000 2015\n",
       "25    Thu Aug 27 19:25:14 +0000 2015\n",
       "26    Thu Aug 27 01:48:47 +0000 2015\n",
       "27    Thu Aug 27 01:42:01 +0000 2015\n",
       "28    Wed Aug 26 21:41:24 +0000 2015\n",
       "29    Wed Aug 26 19:21:21 +0000 2015\n",
       "...                              ...\n",
       "2995  Wed Aug 29 18:41:46 +0000 2012\n",
       "2996  Wed Aug 29 18:40:55 +0000 2012\n",
       "2997  Wed Aug 29 18:40:25 +0000 2012\n",
       "2998  Wed Aug 29 16:42:45 +0000 2012\n",
       "2999  Wed Aug 29 16:22:16 +0000 2012\n",
       "3000  Wed Aug 29 16:19:39 +0000 2012\n",
       "3001  Wed Aug 29 16:17:10 +0000 2012\n",
       "3002  Wed Aug 29 16:15:59 +0000 2012\n",
       "3003  Wed Aug 29 15:36:14 +0000 2012\n",
       "3004  Wed Aug 29 14:22:17 +0000 2012\n",
       "3005  Wed Aug 29 13:59:02 +0000 2012\n",
       "3006  Wed Aug 29 03:09:48 +0000 2012\n",
       "3007  Wed Aug 29 03:08:32 +0000 2012\n",
       "3008  Wed Aug 29 03:06:53 +0000 2012\n",
       "3009  Wed Aug 29 02:49:38 +0000 2012\n",
       "3010  Wed Aug 29 00:55:49 +0000 2012\n",
       "3011  Tue Aug 28 23:08:19 +0000 2012\n",
       "3012  Tue Aug 28 19:30:24 +0000 2012\n",
       "3013  Tue Aug 28 18:48:41 +0000 2012\n",
       "3014  Tue Aug 28 18:23:41 +0000 2012\n",
       "3015  Tue Aug 28 18:22:55 +0000 2012\n",
       "3016  Tue Aug 28 16:35:14 +0000 2012\n",
       "3017  Tue Aug 28 15:37:03 +0000 2012\n",
       "3018  Tue Aug 28 15:23:30 +0000 2012\n",
       "3019  Tue Aug 28 15:20:26 +0000 2012\n",
       "3020  Tue Aug 28 15:09:53 +0000 2012\n",
       "3021  Tue Aug 28 14:29:26 +0000 2012\n",
       "3022  Tue Aug 28 13:24:09 +0000 2012\n",
       "3023  Tue Aug 28 12:38:59 +0000 2012\n",
       "3024  Tue Aug 28 12:38:40 +0000 2012\n",
       "\n",
       "[3025 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'tweets': list(timestamp)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "199\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "26\n",
      "0\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 349: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-4740e8304e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mtweet_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FEMA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mtweet_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\core\\displayhook.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_format_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish_displayhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcull_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\displayhook.pyc\u001b[0m in \u001b[0;36mfinish_displayhook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[0mto_send\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, msg, ident)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# content is already packed, as in a relayed message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\zmq\\utils\\jsonapi.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(o, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'separators'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         sort_keys=sort_keys, **kw).encode(obj)\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 349: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "APP_KEY = 'OHwVhvlnggRRisNErbnQlZzNW'\n",
    "APP_SECRET = '8mretNjRzlpaquepxYFz6Rx4QsZNPdSquz2XkrwKuBWFVx1slD'\n",
    "\n",
    "def get_tweets(user):\n",
    "    twitter = Twython(APP_KEY, APP_SECRET)\n",
    "    user_timeline = twitter.get_user_timeline(screen_name=user, count = 200, include_rts = 1)\n",
    "    tweets = []\n",
    "    hashtags = []\n",
    "    timestamp = []\n",
    "\n",
    "    while len(user_timeline) != 0: \n",
    "        try:\n",
    "            user_timeline = twitter.get_user_timeline(screen_name=user,\n",
    "                                                      include_rts = 1,\n",
    "                                                      count=200,\n",
    "                                                      max_id=user_timeline[len(user_timeline)-1]['id']-1)\n",
    "        except TwythonError as e:\n",
    "            print e\n",
    "        print len(user_timeline)\n",
    "        for tweet in user_timeline:\n",
    "            # Add whatever you want from the tweet, here we just add the text\n",
    "            #tweets.append(tweet['text'].encode('utf-8'))\n",
    "            hashtags.append(tweet['entities']['hashtags'])\n",
    "            timestamp.append(tweet['created_at'].encode('utf-8'))\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    user_timeline = pd.DataFrame({'time' : timestamp, 'tweet' : tweets})\n",
    "    return(user_timeline)\n",
    "\n",
    "tweet_data = get_tweets(\"FEMA\")\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 2799: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1dfc65ba8863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweet_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\core\\displayhook.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_format_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish_displayhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcull_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\displayhook.pyc\u001b[0m in \u001b[0;36mfinish_displayhook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[0mto_send\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, msg, ident)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# content is already packed, as in a relayed message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\IPython\\kernel\\zmq\\session.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\site-packages\\zmq\\utils\\jsonapi.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(o, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'separators'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         sort_keys=sort_keys, **kw).encode(obj)\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 2799: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_histogram(data, time_column):\n",
    "    \n",
    "    # Create bins\n",
    "    min_date = min(data[time_column]).date\n",
    "    max_date = max(data[time_column]).date\n",
    "    bins = pd.date_range(min_date, max_date, freq='D')\n",
    "    \n",
    "    # Find number of values in Bins\n",
    "    bin_values = []\n",
    "    for bin_date in bins:\n",
    "        value = np.sum(data[time_column] < bin_date & bin_date < (data[time_column] + datetime.timedelta(days=1)))\n",
    "        bin_values.append(value)\n",
    "    \n",
    "    positions = np.arange(len(bins))\n",
    "    \n",
    "    # Plot Objects\n",
    "    plt.bar(left = positions, height = bin_values, width = 0,          \n",
    "    plt.xticks(positions, bins)\n",
    "    plt.ylabel('Count of Tweets')\n",
    "    plt.title('Tweets by Day')\n",
    "    plt.show()                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For timeries of events with many short bursts such in our case, a typical time series histogram does not give a lot of information. Although we can see peaks at various times we cannot see what is going on during those \"bursts\". To do this we would have to subset the data for this periods and make our bins smaller.\n",
    "\n",
    "###The Alternative: A Time Map\n",
    "I read about this idea in a recent blog post at District Data Labs:\n",
    "https://districtdatalabs.silvrback.com/time-maps-visualizing-discrete-events-across-many-timescales \n",
    "\n",
    "The author described a technique for visualizing many events across multiple timescales in a single image. It allows the viewer to quickly identify critical features, such as whether events occur on a timescale of milliseconds or months.It also allows the viewer to see if the event is preceded or proceeded by a period of sparse event occurances. It is adopted from the field of chaotic systems, and was originally conceived to study the timing of water drops from a dripping faucet. \n",
    "\n",
    "The graphs shows the time from the previous event to an event as well and the time until the next event. The result is the scatter plot below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"quadrants_N_medium.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Making a Time Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_intervals(data):\n",
    "    data = data.sort(\"time\", ascending = 1)    \n",
    "    data.time_before = data.time - data.time.shift(1)\n",
    "    data.time_after = data.time.shift(-1) - data.time\n",
    "\n",
    "tweet_data = find_intervals(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y = tweet_data.time_after, x = tweet_data.time_before, c = 'red', alpha = .5)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the distinction between the data and it's outliers. The bursts show major events happening while the upper values of the (x, y) axis show really slow periods. By subsetting the bursts of data we can extract the \"major events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
